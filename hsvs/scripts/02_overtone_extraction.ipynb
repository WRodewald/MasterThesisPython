{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overtone Extraction**\n",
    "\n",
    "This script extracts overtone magnitudes and phases with previously extracted pitch and pitch increment trajectories.  \n",
    "Overtones are extracted by per-frame division of source x by complex sinusoidal taking pitch and pitch derivative into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#hsvs includes\n",
    "from hsvs.tools import dataset, framed_audio, magnitude, extract_overtones\n",
    "import hsvs\n",
    "\n",
    "# 3rd party dependencies\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel  = 'a'  # [a,e,i,o,u]\n",
    "singer = 'f6' # [f1 - f9, m1-m11]\n",
    "\n",
    "num_overtones_extracted = 60 # overtones \n",
    "num_overtones_stored    = 40\n",
    "\n",
    "# wav and json file path \n",
    "source_file = dataset.get_sample('scales', 'slow_forte', vowel, singer)[0]\n",
    "data_path   = os.path.abspath(os.path.join(os.path.dirname(hsvs.__file__), os.pardir, 'data'))\n",
    "json_file   = os.path.join(data_path, 'results', vowel + '_' + singer, 'audio.json' )\n",
    "out_file_harm = os.path.join(data_path, 'results', vowel + '_' + singer, 'audio', 'harmonic.wav' )\n",
    "out_file_org  = os.path.join(data_path, 'results', vowel + '_' + singer, 'audio', 'original.wav' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the stored audio json file explicitely with the audio wave file to prevent portability issues.\n",
    "audio = framed_audio.FramedAudio.from_json(json_file, wav_replacement=source_file)\n",
    "\n",
    "#run overtone extraction, pitch and pitch-inc are assumed to be stored as trajectories in the audio object\n",
    "overtones = extract_overtones.extract_overtones_from_audio(audio, num_overtones = num_overtones_extracted)\n",
    "\n",
    "# convert to decibel and normalize\n",
    "overtonesDB  = 20. * np.log10(np.abs(overtones))\n",
    "overtonesDB -= np.max(overtonesDB)\n",
    "\n",
    "# store in json\n",
    "audio.store_trajectory('overtones', overtonesDB[:, 0:num_overtones_stored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 10 overtone trajectories\n",
    "plots = plt.plot(audio.get_time(), overtonesDB[:,0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruction**\n",
    "\n",
    "The following cell reconstructs the audio from the pitch and pitch increment trajectories as well as the overtone data.  \n",
    "Reconstruction is performed per-frame with an overlapp add method and hanning windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthesize audio\n",
    "pitch     = audio.get_trajectory('pitch')\n",
    "pitch_inc = audio.get_trajectory('pitch-inc')\n",
    "\n",
    "x = np.zeros(audio.get_num_frames() * audio.hop_size + audio.block_size)\n",
    "window = 2 * np.hanning(audio.block_size)\n",
    "for i in tqdm(range(audio.get_num_frames())):\n",
    "    frame = extract_overtones.synthesize_overtones(overtones[i,:], pitch[i], pitch_inc[i], audio.fs, audio.block_size)\n",
    "\n",
    "    x0 =  i * audio.hop_size\n",
    "    x1 = x0 + audio.block_size\n",
    "\n",
    "    overlap_factor = 2 * audio.hop_size / audio.block_size \n",
    "    x[x0:x1] += frame * window * overlap_factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store results\n",
    "audio.save_json(json_file=json_file)\n",
    "\n",
    "# create dirs if they don't exist yet\n",
    "audio_path = os.path.dirname(out_file_harm)\n",
    "if not os.path.exists(audio_path):\n",
    "            os.makedirs(audio_path)\n",
    "            \n",
    "org = audio.get_raw()\n",
    "\n",
    "# store synthesized and original audio \n",
    "soundfile.write(out_file_harm, x * (0.5/max(abs(x))), audio.fs)\n",
    "soundfile.write(out_file_org, org * (0.5/max(abs(org))), audio.fs)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitcondaenv2conda68a0a19b354d45eb8db982a605d52750",
   "display_name": "Python 3.7.6 64-bit ('condaenv2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}