{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overtone Extraction**\n",
    "\n",
    "This script extracts overtone magnitudes and phases with previously extracted pitch and pitch increment trajectories.  \n",
    "Overtones are extracted by per-frame division of source x by complex sinusoidal taking pitch and pitch derivative into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#hsvs includes\n",
    "from hsvs.tools import dataset, framed_audio, magnitude, extract_overtones\n",
    "import hsvs\n",
    "\n",
    "# 3rd party dependencies\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vocalset = True # set to true if vocalset directory is not set. If True, uses data/input source samples\n",
    "vowel  = 'a'  # [a,e,i,o,u] or [a,i,o] if no_vocalset == True\n",
    "singer = 'f4' # [f1 - f9, m1-m11] or [f1, f4, f5, f6, f8, m1, m2, m4, m5, m8] if no_vocalset == True\n",
    "\n",
    "num_threads_extraction = 6 # set to number of threads to speed up extractio a bit\n",
    "\n",
    "truncate_audible = True\n",
    "num_overtones_extracted = 60 # overtones \n",
    "num_overtones_stored    = 40\n",
    "\n",
    "# wav and json file path \n",
    "singer_vowel_dir = singer + '_' + vowel\n",
    "data_path   = os.path.abspath(os.path.join(os.path.dirname(hsvs.__file__), os.pardir, 'data'))\n",
    "\n",
    "if(no_vocalset):\n",
    "    source_file = os.path.join(data_path, 'input', singer + '_scales_c_slow_forte_' + vowel + '.wav')\n",
    "else:\n",
    "    source_file = dataset.get_sample('scales', 'slow_forte', vowel, singer)[0]\n",
    "\n",
    "json_file   = os.path.join(data_path, 'results', singer_vowel_dir, 'audio.json' )\n",
    "out_file_harm = os.path.join(data_path, 'results', singer_vowel_dir, 'audio', 'harmonic.wav' )\n",
    "out_file_org  = os.path.join(data_path, 'results', singer_vowel_dir, 'audio', 'original.wav' )\n",
    "\n",
    "print(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading the stored audio json file explicitely with the audio wave file to prevent portability issues.\n",
    "audio = framed_audio.FramedAudio.from_json(json_file, wav_replacement=source_file)\n",
    "\n",
    "#run overtone extraction, pitch and pitch-inc are assumed to be stored as trajectories in the audio object\n",
    "overtones = extract_overtones.extract_overtones_from_audio(audio, num_overtones = num_overtones_extracted, num_threads=num_threads_extraction)\n",
    "\n",
    "# convert to decibel and normalize\n",
    "overtonesDB  = 20. * np.log10(np.abs(overtones))\n",
    "overtonesDB -= np.max(overtonesDB)\n",
    "\n",
    "# store in json\n",
    "audio.store_trajectory('overtones', overtonesDB[:, 0:num_overtones_stored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 10 overtone trajectories\n",
    "plots = plt.plot(audio.get_time(), overtonesDB[:,0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruction**\n",
    "\n",
    "The following cell reconstructs the audio from the pitch and pitch increment trajectories as well as the overtone data.  \n",
    "Reconstruction is performed per-frame with an overlapp add method and hanning windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# synthesize audio\n",
    "pitch     = audio.get_trajectory('pitch')\n",
    "pitch_inc = audio.get_trajectory('pitch-inc')\n",
    "\n",
    "x = np.zeros(audio.get_num_frames() * audio.hop_size + audio.block_size)\n",
    "window = 2 * np.hanning(audio.block_size)\n",
    "for i in tqdm(range(audio.get_num_frames())):\n",
    "    frame = extract_overtones.synthesize_overtones(overtones[i,:], pitch[i], pitch_inc[i], audio.fs, audio.block_size)\n",
    "\n",
    "    x0 =  i * audio.hop_size\n",
    "    x1 = x0 + audio.block_size\n",
    "\n",
    "    overlap_factor = 2 * audio.hop_size / audio.block_size \n",
    "    x[x0:x1] += frame * window * overlap_factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#store results\n",
    "audio.save_json(json_file=json_file)\n",
    "\n",
    "# create dirs if they don't exist yet\n",
    "audio_path = os.path.dirname(out_file_harm)\n",
    "if not os.path.exists(audio_path):\n",
    "            os.makedirs(audio_path)\n",
    "            \n",
    "org = audio.get_raw()\n",
    "\n",
    "# if true, truncates the audio signals to the same length as the synthesized signals\n",
    "if(truncate_audible):\n",
    "    onset, offset = magnitude.get_onset_offset(audio)\n",
    "    onset_audio   = (onset  + 50) * audio.hop_size \n",
    "    offset_audio  = (offset - 50) * audio.hop_size\n",
    "\n",
    "    x_truncated = x[onset_audio:offset_audio]\n",
    "    org_truncated = org[onset_audio:offset_audio]\n",
    "\n",
    "else:\n",
    "    x_truncated = x\n",
    "    org_truncated = org\n",
    "\n",
    "\n",
    "\n",
    "# store synthesized and original audio \n",
    "soundfile.write(out_file_harm, x_truncated  / (max(abs(x_truncated))), audio.fs)\n",
    "soundfile.write(out_file_org, org_truncated / (max(abs(org_truncated))), audio.fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting the kernel to flush unused memory\n",
    "# notification beep.\n",
    "\n",
    "#import numpy as np\n",
    "#import sounddevice\n",
    "#beep = np.sin(np.linspace(0, 1000*np.pi,22050))\n",
    "#sounddevice.play(beep, 44100, blocking=True)\n",
    "\n",
    "#%reset -f\n",
    "#exit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('MT': conda)",
   "metadata": {
    "interpreter": {
     "hash": "44434d2daad41ca3bd3c074deb06713d7e9ad603c2415ae80165678b3585721f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}